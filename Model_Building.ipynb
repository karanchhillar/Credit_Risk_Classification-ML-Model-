{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_recall_fscore_support\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('cleaned_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>pct_tl_open_L6M</th>\n",
       "      <th>pct_tl_closed_L6M</th>\n",
       "      <th>Tot_TL_closed_L12M</th>\n",
       "      <th>pct_tl_closed_L12M</th>\n",
       "      <th>Tot_Missed_Pmnt</th>\n",
       "      <th>CC_TL</th>\n",
       "      <th>Home_TL</th>\n",
       "      <th>PL_TL</th>\n",
       "      <th>Secured_TL</th>\n",
       "      <th>...</th>\n",
       "      <th>last_prod_enq2_ConsumerLoan</th>\n",
       "      <th>last_prod_enq2_HL</th>\n",
       "      <th>last_prod_enq2_PL</th>\n",
       "      <th>last_prod_enq2_others</th>\n",
       "      <th>first_prod_enq2_AL</th>\n",
       "      <th>first_prod_enq2_CC</th>\n",
       "      <th>first_prod_enq2_ConsumerLoan</th>\n",
       "      <th>first_prod_enq2_HL</th>\n",
       "      <th>first_prod_enq2_PL</th>\n",
       "      <th>first_prod_enq2_others</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11672</th>\n",
       "      <td>11672</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  pct_tl_open_L6M  pct_tl_closed_L6M  Tot_TL_closed_L12M  \\\n",
       "11672       11672              0.0                0.0                   1   \n",
       "\n",
       "       pct_tl_closed_L12M  Tot_Missed_Pmnt  CC_TL  Home_TL  PL_TL  Secured_TL  \\\n",
       "11672                 1.0                0      0        0      0           0   \n",
       "\n",
       "       ...  last_prod_enq2_ConsumerLoan  last_prod_enq2_HL  last_prod_enq2_PL  \\\n",
       "11672  ...                        False              False              False   \n",
       "\n",
       "       last_prod_enq2_others  first_prod_enq2_AL  first_prod_enq2_CC  \\\n",
       "11672                   True               False               False   \n",
       "\n",
       "       first_prod_enq2_ConsumerLoan  first_prod_enq2_HL  first_prod_enq2_PL  \\\n",
       "11672                          True               False               False   \n",
       "\n",
       "       first_prod_enq2_others  \n",
       "11672                   False  \n",
       "\n",
       "[1 rows x 56 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Unnamed: 0'] , axis = 1 , inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Approved_Flag']\n",
    "x = df.drop(['Approved_Flag'], axis = 1 )\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          P1       0.84      0.70      0.76      1014\n",
      "          P2       0.80      0.93      0.86      5045\n",
      "          P3       0.44      0.21      0.29      1325\n",
      "          P4       0.72      0.73      0.72      1029\n",
      "\n",
      "    accuracy                           0.76      8413\n",
      "   macro avg       0.70      0.64      0.66      8413\n",
      "weighted avg       0.74      0.76      0.74      8413\n",
      "\n",
      "\n",
      "Accuracy: 0.7636990372043266\n",
      "\n",
      "Class p1:\n",
      "Precision: 0.8370457209847597\n",
      "Recall: 0.7041420118343196\n",
      "F1 Score: 0.7648634172469203\n",
      "\n",
      "Class p2:\n",
      "Precision: 0.7957519116397621\n",
      "Recall: 0.9282457879088206\n",
      "F1 Score: 0.8569075937785909\n",
      "\n",
      "Class p3:\n",
      "Precision: 0.4423380726698262\n",
      "Recall: 0.21132075471698114\n",
      "F1 Score: 0.28600612870275793\n",
      "\n",
      "Class p4:\n",
      "Precision: 0.7178502879078695\n",
      "Recall: 0.7269193391642371\n",
      "F1 Score: 0.7223563495895703\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "\n",
    "rf_classifier = RandomForestClassifier(n_estimators = 200, random_state=42)\n",
    "\n",
    "rf_classifier.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = rf_classifier.predict(x_test)\n",
    "\n",
    "print('Random Forest Classifier Report:')\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print ()\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print ()\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred)\n",
    "\n",
    "\n",
    "for i, v in enumerate(['p1', 'p2', 'p3', 'p4']):\n",
    "    print(f\"Class {v}:\")\n",
    "    print(f\"Precision: {precision[i]}\")\n",
    "    print(f\"Recall: {recall[i]}\")\n",
    "    print(f\"F1 Score: {f1_score[i]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inference:** That random forest is not able to predict P3 as it has very less f1 score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB Classifier Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.76      0.79      1014\n",
      "           1       0.83      0.91      0.87      5045\n",
      "           2       0.48      0.31      0.37      1325\n",
      "           3       0.73      0.74      0.73      1029\n",
      "\n",
      "    accuracy                           0.78      8413\n",
      "   macro avg       0.71      0.68      0.69      8413\n",
      "weighted avg       0.76      0.78      0.76      8413\n",
      "\n",
      "\n",
      "Accuracy: 0.78\n",
      "\n",
      "Class p1:\n",
      "Precision: 0.8370457209847597\n",
      "Recall: 0.7041420118343196\n",
      "F1 Score: 0.7648634172469203\n",
      "\n",
      "Class p2:\n",
      "Precision: 0.7957519116397621\n",
      "Recall: 0.9282457879088206\n",
      "F1 Score: 0.8569075937785909\n",
      "\n",
      "Class p3:\n",
      "Precision: 0.4423380726698262\n",
      "Recall: 0.21132075471698114\n",
      "F1 Score: 0.28600612870275793\n",
      "\n",
      "Class p4:\n",
      "Precision: 0.7178502879078695\n",
      "Recall: 0.7269193391642371\n",
      "F1 Score: 0.7223563495895703\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "xgb_classifier = XGBClassifier(objective='multi:softmax',  num_class=4)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "x_train_xg, x_test_xg, y_train_xg, y_test_xg = train_test_split(x, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "xgb_classifier.fit(x_train_xg, y_train_xg)\n",
    "y_pred_xg = xgb_classifier.predict(x_test_xg)\n",
    "\n",
    "print('XGB Classifier Report:')\n",
    "print(classification_report(y_test_xg, y_pred_xg))\n",
    "\n",
    "accuracy = accuracy_score(y_test_xg, y_pred_xg)\n",
    "print ()\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print ()\n",
    "\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred)\n",
    "\n",
    "for i, v in enumerate(['p1', 'p2', 'p3', 'p4']):\n",
    "    print(f\"Class {v}:\")\n",
    "    print(f\"Precision: {precision[i]}\")\n",
    "    print(f\"Recall: {recall[i]}\")\n",
    "    print(f\"F1 Score: {f1_score[i]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inference:** That XGBoost is better than random forest but also is not able to predict P3 as it has very less f1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "Best parameters for Logistic Regression: {'alpha': 1, 'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200}\n",
      "Best score for Logistic Regression: 0.7791449334133633\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {\n",
    "  # 'colsample_bytree': [ 0.5, 0.9],\n",
    "  'learning_rate'   : [0.001, 0.01, 0.1, 1],\n",
    "  'max_depth'       : [3, 5,],\n",
    "  'alpha'           : [1, 100],\n",
    "  'n_estimators'    : [50,100,200]\n",
    "}\n",
    "xgb_classifier = XGBClassifier()\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "\n",
    "x_train_xg, x_test_xg, y_train_xg, y_test_xg = train_test_split(x, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Perform grid search\n",
    "xgb_grid_search = GridSearchCV(estimator=xgb_classifier, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "xgb_grid_search.fit(x_train_xg, y_train_xg)\n",
    "\n",
    "# Best parameters and score\n",
    "print(\"Best parameters for Logistic Regression:\", xgb_grid_search.best_params_)\n",
    "print(\"Best score for Logistic Regression:\", xgb_grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          P1       0.72      0.73      0.73      1014\n",
      "          P2       0.81      0.83      0.82      5045\n",
      "          P3       0.34      0.32      0.33      1325\n",
      "          P4       0.65      0.62      0.64      1029\n",
      "\n",
      "    accuracy                           0.71      8413\n",
      "   macro avg       0.63      0.63      0.63      8413\n",
      "weighted avg       0.71      0.71      0.71      8413\n",
      "\n",
      "\n",
      "Accuracy: 0.71\n",
      "\n",
      "Class p1:\n",
      "Precision: 0.7205452775073028\n",
      "Recall: 0.7297830374753451\n",
      "F1 Score: 0.7251347378735914\n",
      "\n",
      "Class p2:\n",
      "Precision: 0.8096071567483469\n",
      "Recall: 0.8251734390485629\n",
      "F1 Score: 0.8173161872975361\n",
      "\n",
      "Class p3:\n",
      "Precision: 0.3415409054805401\n",
      "Recall: 0.32452830188679244\n",
      "F1 Score: 0.33281733746130027\n",
      "\n",
      "Class p4:\n",
      "Precision: 0.650761421319797\n",
      "Recall: 0.6229348882410107\n",
      "F1 Score: 0.6365441906653425\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt_model = DecisionTreeClassifier(max_depth=20, min_samples_split=10)\n",
    "dt_model.fit(x_train, y_train)\n",
    "y_pred = dt_model.predict(x_test)\n",
    "print('Decision Tree Classifier Report:')\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print ()\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print ()\n",
    "\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred)\n",
    "\n",
    "for i, v in enumerate(['p1', 'p2', 'p3', 'p4']):\n",
    "    print(f\"Class {v}:\")\n",
    "    print(f\"Precision: {precision[i]}\")\n",
    "    print(f\"Recall: {recall[i]}\")\n",
    "    print(f\"F1 Score: {f1_score[i]}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inference:** Less accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4 KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy: 0.6107215024367051\n",
      "KNN Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          P1       0.58      0.36      0.44      1014\n",
      "          P2       0.67      0.86      0.75      5045\n",
      "          P3       0.29      0.16      0.21      1325\n",
      "          P4       0.40      0.21      0.27      1029\n",
      "\n",
      "    accuracy                           0.61      8413\n",
      "   macro avg       0.48      0.40      0.42      8413\n",
      "weighted avg       0.56      0.61      0.57      8413\n",
      "\n",
      "\n",
      "Accuracy: 0.61\n",
      "\n",
      "Class p1:\n",
      "Precision: 0.5848142164781907\n",
      "Recall: 0.35700197238658776\n",
      "F1 Score: 0.4433557868952847\n",
      "\n",
      "Class p2:\n",
      "Precision: 0.666003367518751\n",
      "Recall: 0.8624380574826561\n",
      "F1 Score: 0.7515978580065642\n",
      "\n",
      "Class p3:\n",
      "Precision: 0.29322268326417705\n",
      "Recall: 0.16\n",
      "F1 Score: 0.20703125000000003\n",
      "\n",
      "Class p4:\n",
      "Precision: 0.395910780669145\n",
      "Recall: 0.20699708454810495\n",
      "F1 Score: 0.27185705169112956\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# K-Nearest Neighbors (KNN)\n",
    "knn_model = KNeighborsClassifier()\n",
    "knn_model.fit(x_train, y_train)\n",
    "knn_predictions = knn_model.predict(x_test)\n",
    "print('KNN Accuracy:', accuracy_score(y_test, knn_predictions))\n",
    "print('KNN Classification Report:')\n",
    "print(classification_report(y_test, knn_predictions))\n",
    "\n",
    "y_pred = knn_predictions\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print ()\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print ()\n",
    "\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred)\n",
    "\n",
    "for i, v in enumerate(['p1', 'p2', 'p3', 'p4']):\n",
    "    print(f\"Class {v}:\")\n",
    "    print(f\"Precision: {precision[i]}\")\n",
    "    print(f\"Recall: {recall[i]}\")\n",
    "    print(f\"F1 Score: {f1_score[i]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "Best parameters for KNN: {'metric': 'manhattan', 'n_neighbors': 9, 'weights': 'uniform'}\n",
      "Best score for KNN: 0.6321060988798364\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Define the parameter grid for KNeighborsClassifier\n",
    "knn_param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 9],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan', 'minkowski']\n",
    "}\n",
    "\n",
    "# Initialize the KNeighborsClassifier\n",
    "knn_model = KNeighborsClassifier()\n",
    "\n",
    "# Perform grid search\n",
    "knn_grid_search = GridSearchCV(estimator=knn_model, param_grid=knn_param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "knn_grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Best parameters and score\n",
    "print(\"Best parameters for KNN:\", knn_grid_search.best_params_)\n",
    "print(\"Best score for KNN:\", knn_grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.6179721859027695\n",
      "Logistic Regression Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          P1       0.57      0.40      0.47      1014\n",
      "          P2       0.63      0.94      0.75      5045\n",
      "          P3       0.00      0.00      0.00      1325\n",
      "          P4       0.41      0.05      0.08      1029\n",
      "\n",
      "    accuracy                           0.62      8413\n",
      "   macro avg       0.40      0.35      0.33      8413\n",
      "weighted avg       0.49      0.62      0.52      8413\n",
      "\n",
      "\n",
      "Accuracy: 0.62\n",
      "\n",
      "Class p1:\n",
      "Precision: 0.5652173913043478\n",
      "Recall: 0.3974358974358974\n",
      "F1 Score: 0.4667052692530399\n",
      "\n",
      "Class p2:\n",
      "Precision: 0.6264678717508906\n",
      "Recall: 0.9411298315163529\n",
      "F1 Score: 0.7522179974651457\n",
      "\n",
      "Class p3:\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1 Score: 0.0\n",
      "\n",
      "Class p4:\n",
      "Precision: 0.41025641025641024\n",
      "Recall: 0.04664723032069971\n",
      "F1 Score: 0.0837696335078534\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "log_reg_model = LogisticRegression(max_iter=200)\n",
    "log_reg_model.fit(x_train, y_train)\n",
    "log_reg_predictions = log_reg_model.predict(x_test)\n",
    "print('Logistic Regression Accuracy:', accuracy_score(y_test, log_reg_predictions))\n",
    "print('Logistic Regression Classification Report:')\n",
    "print(classification_report(y_test, log_reg_predictions))\n",
    "\n",
    "y_pred = log_reg_predictions\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print ()\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print ()\n",
    "\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred)\n",
    "\n",
    "for i, v in enumerate(['p1', 'p2', 'p3', 'p4']):\n",
    "    print(f\"Class {v}:\")\n",
    "    print(f\"Precision: {precision[i]}\")\n",
    "    print(f\"Recall: {recall[i]}\")\n",
    "    print(f\"F1 Score: {f1_score[i]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost is the best model with accuracy of 78"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note : The overall accuracy score of the model is less because they are not able to identify P3 category "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_excel(\"data2.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For P1 categorry.The value of maximun and minimun = 701 - 811\n",
      "For P2 categorry.The value of maximun and minimun = 669 - 700\n",
      "For P3 categorry.The value of maximun and minimun = 489 - 776\n",
      "For P4 categorry.The value of maximun and minimun = 469 - 658\n"
     ]
    }
   ],
   "source": [
    "for i in ['P1' , 'P2', 'P3' , 'P4']:\n",
    "    max_credit_score = df2[df2['Approved_Flag'] == i]['Credit_Score'].max()\n",
    "    min_credit_score = df2[df2['Approved_Flag'] == i]['Credit_Score'].min()\n",
    "\n",
    "    print(f'For {i} categorry.The value of maximun and minimun = {min_credit_score} - {max_credit_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: For P3 categorry.The value of maximun and minimun = 489 - 776\n",
    "#### So it has has wide range of pages so it is difficuit for machine to predict it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to model.pkl\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "model_filename = 'model.pkl'\n",
    "\n",
    "with open(model_filename, 'wb') as file:\n",
    "    pickle.dump(xgb_classifier, file)\n",
    "\n",
    "print(f\"Model saved to {model_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
