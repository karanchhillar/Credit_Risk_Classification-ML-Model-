{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_recall_fscore_support\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('cleaned_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>pct_tl_open_L6M</th>\n",
       "      <th>pct_tl_closed_L6M</th>\n",
       "      <th>Tot_TL_closed_L12M</th>\n",
       "      <th>pct_tl_closed_L12M</th>\n",
       "      <th>Tot_Missed_Pmnt</th>\n",
       "      <th>CC_TL</th>\n",
       "      <th>Home_TL</th>\n",
       "      <th>PL_TL</th>\n",
       "      <th>Secured_TL</th>\n",
       "      <th>...</th>\n",
       "      <th>last_prod_enq2_ConsumerLoan</th>\n",
       "      <th>last_prod_enq2_HL</th>\n",
       "      <th>last_prod_enq2_PL</th>\n",
       "      <th>last_prod_enq2_others</th>\n",
       "      <th>first_prod_enq2_AL</th>\n",
       "      <th>first_prod_enq2_CC</th>\n",
       "      <th>first_prod_enq2_ConsumerLoan</th>\n",
       "      <th>first_prod_enq2_HL</th>\n",
       "      <th>first_prod_enq2_PL</th>\n",
       "      <th>first_prod_enq2_others</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8642</th>\n",
       "      <td>8642</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  pct_tl_open_L6M  pct_tl_closed_L6M  Tot_TL_closed_L12M  \\\n",
       "8642        8642              0.0                0.0                   0   \n",
       "\n",
       "      pct_tl_closed_L12M  Tot_Missed_Pmnt  CC_TL  Home_TL  PL_TL  Secured_TL  \\\n",
       "8642                 0.0                1      0        0      0           2   \n",
       "\n",
       "      ...  last_prod_enq2_ConsumerLoan  last_prod_enq2_HL  last_prod_enq2_PL  \\\n",
       "8642  ...                        False              False              False   \n",
       "\n",
       "      last_prod_enq2_others  first_prod_enq2_AL  first_prod_enq2_CC  \\\n",
       "8642                   True               False               False   \n",
       "\n",
       "      first_prod_enq2_ConsumerLoan  first_prod_enq2_HL  first_prod_enq2_PL  \\\n",
       "8642                         False               False               False   \n",
       "\n",
       "      first_prod_enq2_others  \n",
       "8642                    True  \n",
       "\n",
       "[1 rows x 56 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Unnamed: 0'] , axis = 1 , inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Approved_Flag']\n",
    "x = df.drop(['Approved_Flag'], axis = 1 )\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          P1       0.84      0.70      0.77      1014\n",
      "          P2       0.79      0.93      0.86      5045\n",
      "          P3       0.44      0.21      0.28      1325\n",
      "          P4       0.72      0.72      0.72      1029\n",
      "\n",
      "    accuracy                           0.76      8413\n",
      "   macro avg       0.70      0.64      0.66      8413\n",
      "weighted avg       0.74      0.76      0.74      8413\n",
      "\n",
      "\n",
      "Accuracy: 0.7648876738381077\n",
      "\n",
      "Class p1:\n",
      "Precision: 0.8439716312056738\n",
      "Recall: 0.7041420118343196\n",
      "F1 Score: 0.767741935483871\n",
      "\n",
      "Class p2:\n",
      "Precision: 0.7940283400809717\n",
      "Recall: 0.9330029732408325\n",
      "F1 Score: 0.8579239952610953\n",
      "\n",
      "Class p3:\n",
      "Precision: 0.4444444444444444\n",
      "Recall: 0.20528301886792452\n",
      "F1 Score: 0.2808466701084151\n",
      "\n",
      "Class p4:\n",
      "Precision: 0.7224926971762414\n",
      "Recall: 0.7210884353741497\n",
      "F1 Score: 0.7217898832684825\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "\n",
    "rf_classifier = RandomForestClassifier(n_estimators = 200, random_state=42)\n",
    "\n",
    "rf_classifier.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = rf_classifier.predict(x_test)\n",
    "\n",
    "print('Random Forest Classifier Report:')\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print ()\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print ()\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred)\n",
    "\n",
    "\n",
    "for i, v in enumerate(['p1', 'p2', 'p3', 'p4']):\n",
    "    print(f\"Class {v}:\")\n",
    "    print(f\"Precision: {precision[i]}\")\n",
    "    print(f\"Recall: {recall[i]}\")\n",
    "    print(f\"F1 Score: {f1_score[i]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inference:** That random forest is not able to predict P3 as it has very less f1 score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB Classifier Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.77      0.80      1014\n",
      "           1       0.82      0.91      0.87      5045\n",
      "           2       0.47      0.29      0.36      1325\n",
      "           3       0.72      0.74      0.73      1029\n",
      "\n",
      "    accuracy                           0.78      8413\n",
      "   macro avg       0.71      0.68      0.69      8413\n",
      "weighted avg       0.75      0.78      0.76      8413\n",
      "\n",
      "\n",
      "Accuracy: 0.78\n",
      "\n",
      "Class p1:\n",
      "Precision: 0.8439716312056738\n",
      "Recall: 0.7041420118343196\n",
      "F1 Score: 0.767741935483871\n",
      "\n",
      "Class p2:\n",
      "Precision: 0.7940283400809717\n",
      "Recall: 0.9330029732408325\n",
      "F1 Score: 0.8579239952610953\n",
      "\n",
      "Class p3:\n",
      "Precision: 0.4444444444444444\n",
      "Recall: 0.20528301886792452\n",
      "F1 Score: 0.2808466701084151\n",
      "\n",
      "Class p4:\n",
      "Precision: 0.7224926971762414\n",
      "Recall: 0.7210884353741497\n",
      "F1 Score: 0.7217898832684825\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "xgb_classifier = XGBClassifier(objective='multi:softmax',  num_class=4)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "x_train_xg, x_test_xg, y_train_xg, y_test_xg = train_test_split(x, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "xgb_classifier.fit(x_train_xg, y_train_xg)\n",
    "y_pred_xg = xgb_classifier.predict(x_test_xg)\n",
    "\n",
    "print('XGB Classifier Report:')\n",
    "print(classification_report(y_test_xg, y_pred_xg))\n",
    "\n",
    "accuracy = accuracy_score(y_test_xg, y_pred_xg)\n",
    "print ()\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print ()\n",
    "\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred)\n",
    "\n",
    "for i, v in enumerate(['p1', 'p2', 'p3', 'p4']):\n",
    "    print(f\"Class {v}:\")\n",
    "    print(f\"Precision: {precision[i]}\")\n",
    "    print(f\"Recall: {recall[i]}\")\n",
    "    print(f\"F1 Score: {f1_score[i]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inference:** That XGBoost is better than random forest but also is not able to predict P3 as it has very less f1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "Best parameters for Logistic Regression: {'alpha': 1, 'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100}\n",
      "Best score for Logistic Regression: 0.7794717396146502\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {\n",
    "  # 'colsample_bytree': [ 0.5, 0.9],\n",
    "  'learning_rate'   : [0.001, 0.01, 0.1, 1],\n",
    "  'max_depth'       : [3, 5,],\n",
    "  'alpha'           : [1, 100],\n",
    "  'n_estimators'    : [50,100,200]\n",
    "}\n",
    "xgb_classifier = XGBClassifier()\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "\n",
    "x_train_xg, x_test_xg, y_train_xg, y_test_xg = train_test_split(x, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Perform grid search\n",
    "xgb_grid_search = GridSearchCV(estimator=xgb_classifier, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "xgb_grid_search.fit(x_train_xg, y_train_xg)\n",
    "\n",
    "# Best parameters and score\n",
    "print(\"Best parameters for Logistic Regression:\", xgb_grid_search.best_params_)\n",
    "print(\"Best score for Logistic Regression:\", xgb_grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          P1       0.73      0.72      0.73      1014\n",
      "          P2       0.81      0.83      0.82      5045\n",
      "          P3       0.34      0.31      0.32      1325\n",
      "          P4       0.63      0.63      0.63      1029\n",
      "\n",
      "    accuracy                           0.71      8413\n",
      "   macro avg       0.63      0.62      0.62      8413\n",
      "weighted avg       0.70      0.71      0.71      8413\n",
      "\n",
      "\n",
      "Accuracy: 0.71\n",
      "\n",
      "Class p1:\n",
      "Precision: 0.7279046673286991\n",
      "Recall: 0.722879684418146\n",
      "F1 Score: 0.7253834735279565\n",
      "\n",
      "Class p2:\n",
      "Precision: 0.8092373374733165\n",
      "Recall: 0.8265609514370664\n",
      "F1 Score: 0.817807413218278\n",
      "\n",
      "Class p3:\n",
      "Precision: 0.33797054009819966\n",
      "Recall: 0.31169811320754715\n",
      "F1 Score: 0.3243031016882607\n",
      "\n",
      "Class p4:\n",
      "Precision: 0.6314258001939864\n",
      "Recall: 0.6326530612244898\n",
      "F1 Score: 0.6320388349514564\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt_model = DecisionTreeClassifier(max_depth=20, min_samples_split=10)\n",
    "dt_model.fit(x_train, y_train)\n",
    "y_pred = dt_model.predict(x_test)\n",
    "print('Decision Tree Classifier Report:')\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print ()\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print ()\n",
    "\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred)\n",
    "\n",
    "for i, v in enumerate(['p1', 'p2', 'p3', 'p4']):\n",
    "    print(f\"Class {v}:\")\n",
    "    print(f\"Precision: {precision[i]}\")\n",
    "    print(f\"Recall: {recall[i]}\")\n",
    "    print(f\"F1 Score: {f1_score[i]}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inference:** Less accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4 KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy: 0.5564008082729109\n",
      "KNN Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          P1       0.31      0.14      0.19      1014\n",
      "          P2       0.62      0.86      0.72      5045\n",
      "          P3       0.22      0.10      0.14      1325\n",
      "          P4       0.21      0.06      0.10      1029\n",
      "\n",
      "    accuracy                           0.56      8413\n",
      "   macro avg       0.34      0.29      0.29      8413\n",
      "weighted avg       0.47      0.56      0.49      8413\n",
      "\n",
      "\n",
      "Accuracy: 0.56\n",
      "\n",
      "Class p1:\n",
      "Precision: 0.31042128603104213\n",
      "Recall: 0.13806706114398423\n",
      "F1 Score: 0.19112627986348124\n",
      "\n",
      "Class p2:\n",
      "Precision: 0.6157335223245924\n",
      "Recall: 0.8610505450941526\n",
      "F1 Score: 0.7180165289256197\n",
      "\n",
      "Class p3:\n",
      "Precision: 0.22372881355932203\n",
      "Recall: 0.09962264150943397\n",
      "F1 Score: 0.13785900783289817\n",
      "\n",
      "Class p4:\n",
      "Precision: 0.20504731861198738\n",
      "Recall: 0.06316812439261418\n",
      "F1 Score: 0.09658246656760773\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# K-Nearest Neighbors (KNN)\n",
    "knn_model = KNeighborsClassifier()\n",
    "knn_model.fit(x_train, y_train)\n",
    "knn_predictions = knn_model.predict(x_test)\n",
    "print('KNN Accuracy:', accuracy_score(y_test, knn_predictions))\n",
    "print('KNN Classification Report:')\n",
    "print(classification_report(y_test, knn_predictions))\n",
    "\n",
    "y_pred = knn_predictions\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print ()\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print ()\n",
    "\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred)\n",
    "\n",
    "for i, v in enumerate(['p1', 'p2', 'p3', 'p4']):\n",
    "    print(f\"Class {v}:\")\n",
    "    print(f\"Precision: {precision[i]}\")\n",
    "    print(f\"Recall: {recall[i]}\")\n",
    "    print(f\"F1 Score: {f1_score[i]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "Best parameters for KNN: {'metric': 'manhattan', 'n_neighbors': 9, 'weights': 'uniform'}\n",
      "Best score for KNN: 0.5856884349828023\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Define the parameter grid for KNeighborsClassifier\n",
    "knn_param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 9],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan', 'minkowski']\n",
    "}\n",
    "\n",
    "# Initialize the KNeighborsClassifier\n",
    "knn_model = KNeighborsClassifier()\n",
    "\n",
    "# Perform grid search\n",
    "knn_grid_search = GridSearchCV(estimator=knn_model, param_grid=knn_param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "knn_grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Best parameters and score\n",
    "print(\"Best parameters for KNN:\", knn_grid_search.best_params_)\n",
    "print(\"Best score for KNN:\", knn_grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.6130987757042672\n",
      "Logistic Regression Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          P1       0.57      0.30      0.39      1014\n",
      "          P2       0.62      0.95      0.75      5045\n",
      "          P3       0.00      0.00      0.00      1325\n",
      "          P4       0.39      0.04      0.07      1029\n",
      "\n",
      "    accuracy                           0.61      8413\n",
      "   macro avg       0.39      0.32      0.30      8413\n",
      "weighted avg       0.49      0.61      0.51      8413\n",
      "\n",
      "\n",
      "Accuracy: 0.61\n",
      "\n",
      "Class p1:\n",
      "Precision: 0.5666041275797373\n",
      "Recall: 0.2978303747534517\n",
      "F1 Score: 0.39043309631544926\n",
      "\n",
      "Class p2:\n",
      "Precision: 0.6195316520844055\n",
      "Recall: 0.9544103072348861\n",
      "F1 Score: 0.7513458687680424\n",
      "\n",
      "Class p3:\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1 Score: 0.0\n",
      "\n",
      "Class p4:\n",
      "Precision: 0.3867924528301887\n",
      "Recall: 0.03984450923226433\n",
      "F1 Score: 0.07224669603524228\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "log_reg_model = LogisticRegression(max_iter=200)\n",
    "log_reg_model.fit(x_train, y_train)\n",
    "log_reg_predictions = log_reg_model.predict(x_test)\n",
    "print('Logistic Regression Accuracy:', accuracy_score(y_test, log_reg_predictions))\n",
    "print('Logistic Regression Classification Report:')\n",
    "print(classification_report(y_test, log_reg_predictions))\n",
    "\n",
    "y_pred = log_reg_predictions\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print ()\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print ()\n",
    "\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred)\n",
    "\n",
    "for i, v in enumerate(['p1', 'p2', 'p3', 'p4']):\n",
    "    print(f\"Class {v}:\")\n",
    "    print(f\"Precision: {precision[i]}\")\n",
    "    print(f\"Recall: {recall[i]}\")\n",
    "    print(f\"F1 Score: {f1_score[i]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost is the best model with accuracy of 78"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note : The overall accuracy score of the model is less because they are not able to identify P3 category "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_excel(\"data2.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For P1 categorry.The value of maximun and minimun = 701 - 811\n",
      "For P2 categorry.The value of maximun and minimun = 669 - 700\n",
      "For P3 categorry.The value of maximun and minimun = 489 - 776\n",
      "For P4 categorry.The value of maximun and minimun = 469 - 658\n"
     ]
    }
   ],
   "source": [
    "for i in ['P1' , 'P2', 'P3' , 'P4']:\n",
    "    max_credit_score = df2[df2['Approved_Flag'] == i]['Credit_Score'].max()\n",
    "    min_credit_score = df2[df2['Approved_Flag'] == i]['Credit_Score'].min()\n",
    "\n",
    "    print(f'For {i} categorry.The value of maximun and minimun = {min_credit_score} - {max_credit_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: For P3 categorry.The value of maximun and minimun = 489 - 776\n",
    "#### So it has has wide range of pages so it is difficuit for machine to predict it"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
