{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import chi2_contingency\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from scipy.stats import f_oneway "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Understand the Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_excel(\"data1.xlsx\")\n",
    "df2 = pd.read_excel(\"data2.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n",
      "Index(['PROSPECTID', 'Total_TL', 'Tot_Closed_TL', 'Tot_Active_TL',\n",
      "       'Total_TL_opened_L6M', 'Tot_TL_closed_L6M', 'pct_tl_open_L6M',\n",
      "       'pct_tl_closed_L6M', 'pct_active_tl', 'pct_closed_tl',\n",
      "       'Total_TL_opened_L12M', 'Tot_TL_closed_L12M', 'pct_tl_open_L12M',\n",
      "       'pct_tl_closed_L12M', 'Tot_Missed_Pmnt', 'Auto_TL', 'CC_TL',\n",
      "       'Consumer_TL', 'Gold_TL', 'Home_TL', 'PL_TL', 'Secured_TL',\n",
      "       'Unsecured_TL', 'Other_TL', 'Age_Oldest_TL', 'Age_Newest_TL'],\n",
      "      dtype='object')\n",
      "62\n",
      "Index(['PROSPECTID', 'time_since_recent_payment',\n",
      "       'time_since_first_deliquency', 'time_since_recent_deliquency',\n",
      "       'num_times_delinquent', 'max_delinquency_level',\n",
      "       'max_recent_level_of_deliq', 'num_deliq_6mts', 'num_deliq_12mts',\n",
      "       'num_deliq_6_12mts', 'max_deliq_6mts', 'max_deliq_12mts',\n",
      "       'num_times_30p_dpd', 'num_times_60p_dpd', 'num_std', 'num_std_6mts',\n",
      "       'num_std_12mts', 'num_sub', 'num_sub_6mts', 'num_sub_12mts', 'num_dbt',\n",
      "       'num_dbt_6mts', 'num_dbt_12mts', 'num_lss', 'num_lss_6mts',\n",
      "       'num_lss_12mts', 'recent_level_of_deliq', 'tot_enq', 'CC_enq',\n",
      "       'CC_enq_L6m', 'CC_enq_L12m', 'PL_enq', 'PL_enq_L6m', 'PL_enq_L12m',\n",
      "       'time_since_recent_enq', 'enq_L12m', 'enq_L6m', 'enq_L3m',\n",
      "       'MARITALSTATUS', 'EDUCATION', 'AGE', 'GENDER', 'NETMONTHLYINCOME',\n",
      "       'Time_With_Curr_Empr', 'pct_of_active_TLs_ever',\n",
      "       'pct_opened_TLs_L6m_of_L12m', 'pct_currentBal_all_TL', 'CC_utilization',\n",
      "       'CC_Flag', 'PL_utilization', 'PL_Flag', 'pct_PL_enq_L6m_of_L12m',\n",
      "       'pct_CC_enq_L6m_of_L12m', 'pct_PL_enq_L6m_of_ever',\n",
      "       'pct_CC_enq_L6m_of_ever', 'max_unsec_exposure_inPct', 'HL_Flag',\n",
      "       'GL_Flag', 'last_prod_enq2', 'first_prod_enq2', 'Credit_Score',\n",
      "       'Approved_Flag'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(len(df1.columns))\n",
    "print(df1.columns)\n",
    "print(len(df2.columns))\n",
    "print(df2.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a description of each feature in the df1\n",
    "\n",
    "1. **PROSPECTID**: Unique identifier for each customer or prospect.\n",
    "2. **Total_TL**: Total number of trade lines (credit accounts) held by the customer.\n",
    "3. **Tot_Closed_TL**: Total number of closed trade lines.\n",
    "4. **Tot_Active_TL**: Total number of active trade lines.\n",
    "5. **Total_TL_opened_L6M**: Number of trade lines opened in the last 6 months.\n",
    "6. **Tot_TL_closed_L6M**: Number of trade lines closed in the last 6 months.\n",
    "7. **pct_tl_open_L6M**: Percentage of trade lines opened in the last 6 months.\n",
    "8. **pct_tl_closed_L6M**: Percentage of trade lines closed in the last 6 months.\n",
    "9. **pct_active_tl**: Percentage of active trade lines.\n",
    "10. **pct_closed_tl**: Percentage of closed trade lines.\n",
    "11. **Total_TL_opened_L12M**: Number of trade lines opened in the last 12 months.\n",
    "12. **Tot_TL_closed_L12M**: Number of trade lines closed in the last 12 months.\n",
    "13. **pct_tl_open_L12M**: Percentage of trade lines opened in the last 12 months.\n",
    "14. **pct_tl_closed_L12M**: Percentage of trade lines closed in the last 12 months.\n",
    "15. **Tot_Missed_Pmnt**: Total number of missed payments by the customer.\n",
    "16. **Auto_TL**: Number of auto loan trade lines.\n",
    "17. **CC_TL**: Number of credit card trade lines.\n",
    "18. **Consumer_TL**: Number of consumer loan trade lines.\n",
    "19. **Gold_TL**: Number of gold loan trade lines.\n",
    "20. **Home_TL**: Number of home loan trade lines.\n",
    "21. **PL_TL**: Number of personal loan trade lines.\n",
    "22. **Secured_TL**: Number of secured loan trade lines.\n",
    "23. **Unsecured_TL**: Number of unsecured loan trade lines.\n",
    "24. **Other_TL**: Number of other types of trade lines.\n",
    "25. **Age_Oldest_TL**: Age of the oldest trade line.\n",
    "26. **Age_Newest_TL**: Age of the newest trade line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a description of each feature in the df2:\n",
    "\n",
    "1. **PROSPECTID**: Unique identifier for each customer or prospect.\n",
    "2. **time_since_recent_payment**: Time elapsed since the most recent payment.\n",
    "3. **time_since_first_deliquency**: Time elapsed since the first delinquency.\n",
    "4. **time_since_recent_deliquency**: Time elapsed since the most recent delinquency.\n",
    "5. **num_times_delinquent**: Number of times the customer has been delinquent.\n",
    "6. **max_delinquency_level**: Highest level of delinquency recorded.\n",
    "7. **max_recent_level_of_deliq**: Highest level of recent delinquency.\n",
    "8. **num_deliq_6mts**: Number of delinquencies in the last 6 months.\n",
    "9. **num_deliq_12mts**: Number of delinquencies in the last 12 months.\n",
    "10. **num_deliq_6_12mts**: Number of delinquencies between 6 and 12 months ago.\n",
    "11. **max_deliq_6mts**: Maximum level of delinquency in the last 6 months.\n",
    "12. **max_deliq_12mts**: Maximum level of delinquency in the last 12 months.\n",
    "13. **num_times_30p_dpd**: Number of times 30+ days past due.\n",
    "14. **num_times_60p_dpd**: Number of times 60+ days past due.\n",
    "15. **num_std**: Number of standard loan accounts.\n",
    "16. **num_std_6mts**: Number of standard loan accounts in the last 6 months.\n",
    "17. **num_std_12mts**: Number of standard loan accounts in the last 12 months.\n",
    "18. **num_sub**: Number of subprime loan accounts.\n",
    "19. **num_sub_6mts**: Number of subprime loan accounts in the last 6 months.\n",
    "20. **num_sub_12mts**: Number of subprime loan accounts in the last 12 months.\n",
    "21. **num_dbt**: Number of debt accounts.\n",
    "22. **num_dbt_6mts**: Number of debt accounts in the last 6 months.\n",
    "23. **num_dbt_12mts**: Number of debt accounts in the last 12 months.\n",
    "24. **num_lss**: Number of loss accounts.\n",
    "25. **num_lss_6mts**: Number of loss accounts in the last 6 months.\n",
    "26. **num_lss_12mts**: Number of loss accounts in the last 12 months.\n",
    "27. **recent_level_of_deliq**: Recent level of delinquency.\n",
    "28. **tot_enq**: Total number of credit inquiries.\n",
    "29. **CC_enq**: Number of credit card inquiries.\n",
    "30. **CC_enq_L6m**: Number of credit card inquiries in the last 6 months.\n",
    "31. **CC_enq_L12m**: Number of credit card inquiries in the last 12 months.\n",
    "32. **PL_enq**: Number of personal loan inquiries.\n",
    "33. **PL_enq_L6m**: Number of personal loan inquiries in the last 6 months.\n",
    "34. **PL_enq_L12m**: Number of personal loan inquiries in the last 12 months.\n",
    "35. **time_since_recent_enq**: Time elapsed since the most recent inquiry.\n",
    "36. **enq_L12m**: Number of inquiries in the last 12 months.\n",
    "37. **enq_L6m**: Number of inquiries in the last 6 months.\n",
    "38. **enq_L3m**: Number of inquiries in the last 3 months.\n",
    "39. **MARITALSTATUS**: Marital status of the customer.\n",
    "40. **EDUCATION**: Educational level of the customer.\n",
    "41. **AGE**: Age of the customer.\n",
    "42. **GENDER**: Gender of the customer.\n",
    "43. **NETMONTHLYINCOME**: Net monthly income of the customer.\n",
    "44. **Time_With_Curr_Empr**: Time spent with the current employer.\n",
    "45. **pct_of_active_TLs_ever**: Percentage of active trade lines ever held.\n",
    "46. **pct_opened_TLs_L6m_of_L12m**: Percentage of trade lines opened in the last 6 months relative to the last 12 months.\n",
    "47. **pct_currentBal_all_TL**: Percentage of current balance across all trade lines.\n",
    "48. **CC_utilization**: Utilization rate of credit card trade lines.\n",
    "49. **CC_Flag**: Indicator if the customer has credit card trade lines.\n",
    "50. **PL_utilization**: Utilization rate of personal loan trade lines.\n",
    "51. **PL_Flag**: Indicator if the customer has personal loan trade lines.\n",
    "52. **pct_PL_enq_L6m_of_L12m**: Percentage of personal loan inquiries in the last 6 months relative to the last 12 months.\n",
    "53. **pct_CC_enq_L6m_of_L12m**: Percentage of credit card inquiries in the last 6 months relative to the last 12 months.\n",
    "54. **pct_PL_enq_L6m_of_ever**: Percentage of personal loan inquiries in the last 6 months relative to all personal loan inquiries ever.\n",
    "55. **pct_CC_enq_L6m_of_ever**: Percentage of credit card inquiries in the last 6 months relative to all credit card inquiries ever.\n",
    "56. **max_unsec_exposure_inPct**: Maximum unsecured exposure as a percentage of total credit.\n",
    "57. **HL_Flag**: Indicator if the customer has home loan trade lines.\n",
    "58. **GL_Flag**: Indicator if the customer has gold loan trade lines.\n",
    "59. **last_prod_enq2**: Time elapsed since the last product inquiry.\n",
    "60. **first_prod_enq2**: Time elapsed since the first product inquiry.\n",
    "61. **Credit_Score**: Credit score of the customer.\n",
    "62. **Approved_Flag**: Indicator if the customer's credit application was approved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Data Cleaning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are some values like -99999 in both df1 and df2 handling them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def columns_with_99999(df):\n",
    "    columns_to_remove = []\n",
    "    filter_columns = []\n",
    "    for i in df.columns:\n",
    "        if df.loc[df[i] == -99999].shape[0] > 10000: # removing the entire col\n",
    "            columns_to_remove.append(i)\n",
    "        elif df.loc[df[i] == -99999].shape[0] > 0: # removing only the rows\n",
    "            filter_columns.append(i)\n",
    "    \n",
    "    return columns_to_remove,filter_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "['Age_Oldest_TL', 'Age_Newest_TL']\n",
      "[]\n",
      "['time_since_recent_payment', 'tot_enq', 'CC_enq', 'CC_enq_L6m', 'CC_enq_L12m', 'PL_enq', 'PL_enq_L6m', 'PL_enq_L12m', 'time_since_recent_enq', 'enq_L12m', 'enq_L6m', 'enq_L3m', 'pct_currentBal_all_TL']\n"
     ]
    }
   ],
   "source": [
    "columns_to_remove_in_df1 , filter_columns_df1 = columns_with_99999(df1)\n",
    "columns_to_remove_in_df2 , filter_columns_df2 = columns_with_99999(df2)\n",
    "\n",
    "print(columns_to_remove_in_df1)\n",
    "print(filter_columns_df1)\n",
    "print(columns_to_remove_in_df1)\n",
    "print(filter_columns_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51336, 26)\n",
      "(51336, 62)\n"
     ]
    }
   ],
   "source": [
    "# before\n",
    "print(df1.shape)\n",
    "print(df2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.drop(columns_to_remove_in_df1 , axis= 1 , inplace=True)\n",
    "df2.drop(columns_to_remove_in_df2 , axis= 1 , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in filter_columns_df1:\n",
    "    df1 = df1.loc[df1[i] != -99999]\n",
    "\n",
    "for i in filter_columns_df2:\n",
    "    df2 = df2.loc[df2[i] != -99999]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51296, 26)\n",
      "(42066, 54)\n"
     ]
    }
   ],
   "source": [
    "# after\n",
    "print(df1.shape)\n",
    "print(df2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# checking any null value\n",
    "print(df1.isna().sum().sum())\n",
    "print(df2.isna().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now joining df1 and df2 into df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROSPECTID\n"
     ]
    }
   ],
   "source": [
    "# checking the common columns\n",
    "for i in df1.columns:\n",
    "    for j in df2.columns:\n",
    "        if i == j:\n",
    "            print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performing inner join on df1 and df2 to avoid null values\n",
    "df = pd.merge(df1,df2,on='PROSPECTID',how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42064, 79)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Data Transformation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.1 Data filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#identifying numerical and categorical columns\n",
    "\n",
    "numerical_columns = []\n",
    "categorical_columns = []\n",
    "\n",
    "for i in df.columns:\n",
    "    if df[i].dtype == 'object':\n",
    "        categorical_columns.append(i)\n",
    "    else:\n",
    "        numerical_columns.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MARITALSTATUS',\n",
       " 'EDUCATION',\n",
       " 'GENDER',\n",
       " 'last_prod_enq2',\n",
       " 'first_prod_enq2',\n",
       " 'Approved_Flag']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing Approved_Flag as this is target \n",
    "categorical_columns.remove('Approved_Flag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MARITALSTATUS\n",
      "Married    30886\n",
      "Single     11178\n",
      "Name: count, dtype: int64\n",
      "---------------------------------\n",
      "EDUCATION\n",
      "GRADUATE          14140\n",
      "12TH              11703\n",
      "SSC                7241\n",
      "UNDER GRADUATE     4572\n",
      "OTHERS             2291\n",
      "POST-GRADUATE      1898\n",
      "PROFESSIONAL        219\n",
      "Name: count, dtype: int64\n",
      "---------------------------------\n",
      "GENDER\n",
      "M    37345\n",
      "F     4719\n",
      "Name: count, dtype: int64\n",
      "---------------------------------\n",
      "last_prod_enq2\n",
      "ConsumerLoan    16480\n",
      "others          13653\n",
      "PL               7553\n",
      "CC               2195\n",
      "AL               1353\n",
      "HL                830\n",
      "Name: count, dtype: int64\n",
      "---------------------------------\n",
      "first_prod_enq2\n",
      "others          20640\n",
      "ConsumerLoan    11075\n",
      "PL               4431\n",
      "AL               2641\n",
      "CC               1988\n",
      "HL               1289\n",
      "Name: count, dtype: int64\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "# seeing all value counts\n",
    "for i in categorical_columns:\n",
    "    print(df[i].value_counts())\n",
    "    print(\"---------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking association between two categorical variables (CHI-SQUARE TEST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "since all the categorical columns p-value <= 0.05 so we will select all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MARITALSTATUS --- 3.578180861038862e-233\n",
      "EDUCATION --- 2.6942265249737532e-30\n",
      "GENDER --- 1.907936100186563e-05\n",
      "last_prod_enq2 --- 0.0\n",
      "first_prod_enq2 --- 7.84997610555419e-287\n"
     ]
    }
   ],
   "source": [
    "# Chi-square test\n",
    "from scipy.stats import chi2_contingency\n",
    "for i in categorical_columns:\n",
    "    chi2, pval, _, _ = chi2_contingency(pd.crosstab(df[i], df['Approved_Flag']))\n",
    "    print(i, '---', pval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variance Inflation Factor (VIF) is a measure used to detect multicollinearity in regression analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VIF for numerical columns\n",
    "numeric_columns = []\n",
    "for i in df.columns:\n",
    "    if df[i].dtype != 'object' and i not in ['PROSPECTID','Approved_Flag']:\n",
    "        numeric_columns.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multicollinearity vs Correlation\n",
    "\n",
    "Multicollinearity = Predictability of each features by other features\n",
    "\n",
    "Correlation is specific to linear realtionships between columns\n",
    "in convex function (y = X^2), corelation give misleading values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Multicolinearity__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variance Inflation Factor\n",
    "\n",
    "Used to identify multicollinearity among IVs\n",
    "\n",
    "Takes R-squared value for each IV and eliminate if crosses a threshold\n",
    "1/(1-R^2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VIF ranges from 1 from infinity\n",
    "\n",
    "1 : No multicollinearity\n",
    "\n",
    "1 to 5 : Low multicollinearity\n",
    "\n",
    "5 to 10 :Moderate multicollinearity\n",
    "\n",
    "VIF above 10 : High multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 --- inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 --- inf\n",
      "0 --- 11.320180023967996\n",
      "0 --- 8.363698035000336\n",
      "0 --- 6.520647877790928\n",
      "0 --- 5.149501618212625\n",
      "1 --- 2.611111040579735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 --- inf\n",
      "2 --- 1788.7926256209232\n",
      "2 --- 8.601028256477228\n",
      "2 --- 3.8328007921530785\n",
      "3 --- 6.099653381646739\n",
      "3 --- 5.581352009642762\n",
      "4 --- 1.985584353098778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 --- inf\n",
      "5 --- 4.809538302819343\n",
      "6 --- 23.270628983464636\n",
      "6 --- 30.595522588100053\n",
      "6 --- 4.3843464059655854\n",
      "7 --- 3.064658415523423\n",
      "8 --- 2.898639771299253\n",
      "9 --- 4.377876915347324\n",
      "10 --- 2.207853583695844\n",
      "11 --- 4.916914200506864\n",
      "12 --- 5.214702030064725\n",
      "13 --- 3.3861625024231476\n",
      "14 --- 7.840583309478997\n",
      "14 --- 5.255034641721438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 --- inf\n",
      "15 --- 7.380634506427232\n",
      "15 --- 1.4210050015175733\n",
      "16 --- 8.083255010190316\n",
      "16 --- 1.6241227524040112\n",
      "17 --- 7.257811920140003\n",
      "17 --- 15.59624383268298\n",
      "17 --- 1.825857047132431\n",
      "18 --- 1.5080839450032664\n",
      "19 --- 2.172088834824577\n",
      "20 --- 2.62339755352723\n",
      "21 --- 2.2959970812106176\n",
      "22 --- 7.360578319196439\n",
      "22 --- 2.1602387773102554\n",
      "23 --- 2.8686288267891458\n",
      "24 --- 6.458218003637277\n",
      "24 --- 2.8474118865638265\n",
      "25 --- 4.753198156284083\n",
      "26 --- 16.22735475594825\n",
      "26 --- 6.424377256363877\n",
      "26 --- 8.887080381808687\n",
      "26 --- 2.3804746142952653\n",
      "27 --- 8.609513476514548\n",
      "27 --- 13.06755093547673\n",
      "27 --- 3.500040056654654\n",
      "28 --- 1.9087955874813773\n",
      "29 --- 17.006562234161628\n",
      "29 --- 10.730485153719197\n",
      "29 --- 2.3538497522950275\n",
      "30 --- 22.104855915136433\n",
      "30 --- 2.7971639638512906\n",
      "31 --- 3.4241712032176985\n",
      "32 --- 10.175021454450935\n",
      "32 --- 6.408710354561301\n",
      "32 --- 1.001151196262561\n",
      "33 --- 3.069197305397274\n",
      "34 --- 2.8091261600643715\n",
      "35 --- 20.249538381980678\n",
      "35 --- 15.864576541593774\n",
      "35 --- 1.8331649740532172\n",
      "36 --- 1.5680839909542037\n",
      "37 --- 1.9307572353811682\n",
      "38 --- 4.331265056645247\n",
      "39 --- 9.390334396150173\n"
     ]
    }
   ],
   "source": [
    "# VIF sequentially check\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "vif_data = df[numeric_columns]\n",
    "total_columns = vif_data.shape[1]\n",
    "columns_to_be_kept = []\n",
    "column_index = 0\n",
    "\n",
    "\n",
    "\n",
    "for i in range (0,total_columns):\n",
    "    \n",
    "    vif_value = variance_inflation_factor(vif_data, column_index)\n",
    "    print (column_index,'---',vif_value)\n",
    "    \n",
    "    \n",
    "    if vif_value <= 6:\n",
    "        columns_to_be_kept.append( numeric_columns[i] )\n",
    "        column_index = column_index+1\n",
    "    \n",
    "    else:\n",
    "        vif_data = vif_data.drop([ numeric_columns[i] ] , axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(columns_to_be_kept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check Anova for columns_to_be_kept \n",
    "\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "columns_to_be_kept_numerical = []\n",
    "\n",
    "for i in columns_to_be_kept:\n",
    "    a = list(df[i])  \n",
    "    b = list(df['Approved_Flag'])  \n",
    "    \n",
    "    group_P1 = [value for value, group in zip(a, b) if group == 'P1']\n",
    "    group_P2 = [value for value, group in zip(a, b) if group == 'P2']\n",
    "    group_P3 = [value for value, group in zip(a, b) if group == 'P3']\n",
    "    group_P4 = [value for value, group in zip(a, b) if group == 'P4']\n",
    "\n",
    "\n",
    "    f_statistic, p_value = f_oneway(group_P1, group_P2, group_P3, group_P4)\n",
    "\n",
    "    if p_value <= 0.05:\n",
    "        columns_to_be_kept_numerical.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(columns_to_be_kept_numerical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# listing all the final features\n",
    "features = columns_to_be_kept_numerical + categorical_columns\n",
    "df = df[features + ['Approved_Flag']] # adding the target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2 Encode categorical features (e.g., one-hot encoding, label encoding)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Married' 'Single']\n",
      "['12TH' 'GRADUATE' 'SSC' 'POST-GRADUATE' 'UNDER GRADUATE' 'OTHERS'\n",
      " 'PROFESSIONAL']\n",
      "['M' 'F']\n",
      "['PL' 'ConsumerLoan' 'AL' 'CC' 'others' 'HL']\n",
      "['PL' 'ConsumerLoan' 'others' 'AL' 'HL' 'CC']\n"
     ]
    }
   ],
   "source": [
    "print(df['MARITALSTATUS'].unique())\n",
    "print(df['EDUCATION'].unique())\n",
    "print(df['GENDER'].unique())\n",
    "print(df['last_prod_enq2'].unique())\n",
    "print(df['first_prod_enq2'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can only label encode education column as other columns doesnot make any sense. for eg for 'MARITALSTATUS' there are 2 unique values = ['Married' 'Single'] and making married = 1 and Single = 0 does not make any sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordinal feature -- EDUCATION\n",
    "# SSC            : 1\n",
    "# 12TH           : 2\n",
    "# GRADUATE       : 3\n",
    "# UNDER GRADUATE : 3\n",
    "# POST-GRADUATE  : 4\n",
    "# OTHERS         : 1\n",
    "# PROFESSIONAL   : 3\n",
    "\n",
    "\n",
    "# Others has to be verified by the business end user "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Label encoding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manual label encoding\n",
    "df.loc[df['EDUCATION'] == 'SSC',['EDUCATION']]              = 1\n",
    "df.loc[df['EDUCATION'] == '12TH',['EDUCATION']]             = 2\n",
    "df.loc[df['EDUCATION'] == 'GRADUATE',['EDUCATION']]         = 3\n",
    "df.loc[df['EDUCATION'] == 'UNDER GRADUATE',['EDUCATION']]   = 3\n",
    "df.loc[df['EDUCATION'] == 'POST-GRADUATE',['EDUCATION']]    = 4\n",
    "df.loc[df['EDUCATION'] == 'OTHERS',['EDUCATION']]           = 1\n",
    "df.loc[df['EDUCATION'] == 'PROFESSIONAL',['EDUCATION']]     = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['EDUCATION'] = df['EDUCATION'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**One hot encoding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding\n",
    "df_encoded = pd.get_dummies(df, columns=['MARITALSTATUS','GENDER', 'last_prod_enq2' ,'first_prod_enq2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded.to_csv('cleaned_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
